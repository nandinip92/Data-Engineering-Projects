{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps for the ETL process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import boto3 \n",
    "import json\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get the configurations to connect to Redshift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "(HOST,DB_NAME, DB_USER, DB_PASSWORD, DB_PORT) = config['CLUSTER'].values()\n",
    "\n",
    "IAM_ROLE_ARN   = config.get(\"IAM_ROLE\",\"ARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to Redshift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn=\"postgresql://{}:{}@{}:{}/{}\".format(DB_USER, DB_PASSWORD, HOST, DB_PORT,DB_NAME)\n",
    "print(conn)\n",
    "%sql $conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating Tables\n",
    "- Write the `CREATE` statements for all the tables in the `create_tables.py`\n",
    "- Run `create_tables.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run create_tables.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check the Sample data in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-01-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='song_data/A/A/A/TRAAANK128F428B515.json')\n"
     ]
    }
   ],
   "source": [
    "#Checking the data objects in S3\n",
    "s3 = boto3.resource('s3',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                   )\n",
    "\n",
    "sampleDbBucket =  s3.Bucket(\"udacity-dend\")\n",
    "\n",
    "for obj in sampleDbBucket.objects.filter(Prefix=\"log_data/2018/11/2018-11-01\"):\n",
    "    print(obj)\n",
    "\n",
    "for obj in sampleDbBucket.objects.filter(Prefix=\"song_data/A/A/A/TRAAANK128F428B515.json\"):\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Copying Sample data from S3 to the stage tables using <span style = \"color:red\"> COPY </span>\n",
    " - Write the `COPY` statements in the `sql_queries.py`\n",
    " ***NOTE :*** Following copy statements will load only with few records for testing\n",
    "\n",
    "###  <span style = \"color:orange\"> ST_Events </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "qry = \"\"\"\n",
    "     COPY ST_Events from {} \n",
    "     credentials 'aws_iam_role={}' \n",
    "     format as json {}\n",
    "     compupdate off\n",
    "     region 'us-west-2';\"\"\".format(config.get(\"S3\",\"LOG_DATA\"),IAM_ROLE_ARN,config.get(\"S3\",\"LOG_JSONPATH\"))\n",
    "\n",
    "%sql $qry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:orange\"> ST_Songs </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "qry = \"\"\"\n",
    "    COPY ST_songs from 's3://udacity-dend/song_data/A/A/A/TRAAANK128F428B515.json' \n",
    "     credentials 'aws_iam_role={}' \n",
    "     format json 'auto'\n",
    "     compupdate off\n",
    "     region 'us-west-2';\n",
    "\"\"\".format(IAM_ROLE_ARN)\n",
    "\n",
    "%sql $qry\n",
    "#config.get(\"S3\",\"SONG_DATA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Inserting into Spatkify schema tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sql_queries import copy_table_queries, insert_table_queries\n",
    "import re\n",
    "for query in insert_table_queries:\n",
    "        table_name = re.findall(r'INSERT INTO\\ (.+?)\\ ',query)\n",
    "        try:\n",
    "            cur.execute(query)\n",
    "            conn.commit()\n",
    "            print(\"'{}'  Insert Successful...!!!\".format(table_name[0]))\n",
    "        except psycopg2.Error as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"select * from (SELECT user_id,count(*) c FROM users group by user_id ) where c>1\")\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "    print(row)\n",
    "    row = cur.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Steps for Deleting the duplicate records and Inserting with latest data in `Users` table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Getting the userIds with duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate recodrs for userIds : ('15', '16', '29', '36', '49', '80', '85', '88')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "query = \"\"\"select user_id from (SELECT user_id,count(*) c FROM users group by user_id ) where c>1\"\"\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "df.count\n",
    "user_ids = tuple(df['user_id'])\n",
    "print(\"Duplicate recodrs for userIds :\",user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Following is the query to get the most recent data of the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"select MAX(ts) as max_time, \\\n",
    "            userId FROM ST_Events WHERE userId IN {} \\\n",
    "            GROUP BY userId ORDER BY userId\"\"\".format(user_ids)\n",
    "df = pd.read_sql_query(query,conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Query with converted timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = \"\"\"select MAX(TIMESTAMP 'epoch' +  ts/1000 * interval '1 second') as max_time, \\\n",
    " #           userId, level FROM ST_Events WHERE userId IN {} \\\n",
    " #           GROUP BY userId,level ORDER BY userId\"\"\".format(user_ids)\n",
    "#df = pd.read_sql_query(query,conn)\n",
    "#df\n",
    "max_time = \"\"\"select MAX(TIMESTAMP 'epoch' +  ts/1000 * interval '1 second') as max_time, \\\n",
    "                userId FROM ST_Events WHERE userId IN {} \\\n",
    "                GROUP BY userId ORDER BY userId\"\"\".format(user_ids)\n",
    "recent_time_df = pd.read_sql_query(max_time,conn)\n",
    "recent_time_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Following snippet is to fecth the most recent data of the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('15', 'Lily', 'Koch', 'F', 'paid'),\n",
       " ('16', 'Rylan', 'George', 'M', 'paid'),\n",
       " ('29', 'Jacqueline', 'Lynch', 'F', 'paid'),\n",
       " ('36', 'Matthew', 'Jones', 'M', 'paid'),\n",
       " ('49', 'Chloe', 'Cuevas', 'F', 'paid'),\n",
       " ('80', 'Tegan', 'Levine', 'F', 'paid'),\n",
       " ('85', 'Kinsley', 'Young', 'F', 'paid'),\n",
       " ('88', 'Mohammad', 'Rodriguez', 'M', 'paid')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ts = \"\"\" SELECT max_time FROM (SELECT MAX(ts) as max_time, \\\n",
    "                                    userId FROM ST_Events WHERE userId IN {} \\\n",
    "                                    GROUP BY userId ORDER BY userId)\"\"\".format(user_ids)\n",
    "\n",
    "updated_level = \"\"\" SELECT userId, \n",
    "                        firstName,\n",
    "                        lastName,\n",
    "                        gender, level FROM ST_EVENTS \\\n",
    "                    WHERE ts IN ({}) AND userId IN {}\"\"\".format(max_ts,user_ids)\n",
    "cur.execute(updated_level)\n",
    "recent_level = cur.fetchall()\n",
    "recent_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for the duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('15', 2),\n",
       " ('16', 2),\n",
       " ('29', 2),\n",
       " ('36', 2),\n",
       " ('49', 2),\n",
       " ('80', 2),\n",
       " ('85', 2),\n",
       " ('88', 2)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"select * from (SELECT user_id,count(*) c FROM users group by user_id ) where c>1\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. <span style = \"color:orange\">Deleting </span>the duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_query = \"DELETE FROM users WHERE user_id IN {}\".format(user_ids)\n",
    "cur.execute(delete_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4. Inserting with the latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_insert_query = \"INSERT INTO users (user_id, first_name,last_name,gender, level) VALUES  (%s, %s,%s,%s, %s)\"\n",
    "\n",
    "for row in recent_level:\n",
    "    cur.execute(users_insert_query,row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('15', '16', '29', '36', '49', '80', '85', '88')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('15', 'Lily', 'Koch', 'F', 'paid'),\n",
       " ('16', 'Rylan', 'George', 'M', 'paid'),\n",
       " ('29', 'Jacqueline', 'Lynch', 'F', 'paid'),\n",
       " ('36', 'Matthew', 'Jones', 'M', 'paid'),\n",
       " ('49', 'Chloe', 'Cuevas', 'F', 'paid'),\n",
       " ('80', 'Tegan', 'Levine', 'F', 'paid'),\n",
       " ('85', 'Kinsley', 'Young', 'F', 'paid'),\n",
       " ('88', 'Mohammad', 'Rodriguez', 'M', 'paid')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(user_ids)\n",
    "query = \"\"\"SELECT * FROM users WHERE user_id IN {};\"\"\".format(user_ids)\n",
    "cur.execute(query)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_isolation_level = conn.isolation_level\n",
    "print(\"old_isolation_level :\",old_isolation_level)\n",
    "conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "cur.execute(\"VACCUM FULL users to 100 percent;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
